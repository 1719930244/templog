# AI代码生成评测指标SOTA数据验证请求

## 需要验证的数据点

### 1. Bug定位准确率

#### LocAgent
- **声称SOTA**: 95% 函数匹配率 (SWE-bench Lite)
- **来源**: ACL 2025, arXiv:2503.09089
- **需确认**:
  - 这个95%是否准确？
  - 是在SWE-bench Lite还是其他数据集？
  - 使用的模型是Qwen-2.5-Coder-32B吗？

#### GraphLocator
- **声称SOTA**: 函数级recall +19.49%, precision +11.89%
- **来源**: arXiv:2512.22469 (Dec 2024)
- **需确认**:
  - 这个提升是相对于什么基线？
  - 在哪个数据集上测试的？

### 2. 指令遵循率

#### BigCodeBench
- **声称SOTA**: ~60% (GPT-4/Claude-3.5)
- **人类基线**: 97%
- **来源**: ICLR 2025, arXiv:2406.15877
- **需确认**:
  - 当前最高分是多少？
  - 有没有更新的leaderboard数据？

### 3. 代码效率

#### EffiBench
- **声称SOTA**:
  - GPT-4: 3.12x
  - StarCoder2-15B: 2.59x
- **来源**: NeurIPS 2024, arXiv:2402.02037
- **需确认**:
  - 这些数字是否准确？
  - 有没有2025-2026年的更新数据？

### 4. 测试生成质量

#### 变异测试分数 (MuTAP)
- **声称SOTA**: 93.57%
- **传统基线**: Pynguin 65.94%
- **来源**: arXiv:2308.16557
- **需确认**:
  - 这个93.57%是在哪个数据集上？
  - 有没有更新的方法超过这个分数？

#### 测试构建通过率 (TestGenEval)
- **声称SOTA**:
  - Llama 3.1 405B: Build 80%, Pass 73%
  - GPT-4o: Build 75%, Pass 64%
- **来源**: ICLR 2025, arXiv:2410.00752
- **需确认**:
  - 这些数字是否来自官方论文？
  - 有没有更新的模型结果？

### 5. 安全性

#### CyberSecEval 2
- **声称SOTA**:
  - False Refusal Rate: <15% (GPT-4/Claude-3.5)
  - Prompt Injection: 26-41% (所有模型)
- **来源**: Meta, arXiv:2404.13161
- **需确认**:
  - Prompt Injection的26-41%范围是否准确？
  - 有没有模型突破这个范围？

## 验证方法

1. 查找原始论文的实验结果表格
2. 检查官方leaderboard（如果有）
3. 搜索最新的相关论文引用这些数据
4. 确认数据集版本和评测协议

## 输出格式

对每个数据点，请提供：
- ✅ 确认准确 / ⚠️ 部分准确 / ❌ 不准确
- 原始数据来源（论文章节/表格编号）
- 如有更新数据，提供最新SOTA
- 任何需要注意的细节或限制条件

---

**请求时间**: 2026-03-01
**请求人**: 用于企业内部AI代码生成产品评测提案
