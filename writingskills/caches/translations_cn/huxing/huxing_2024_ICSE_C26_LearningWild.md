# Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively Tuning Pre-trained Code Models
# 野外学习：利用无标签数据有效微调预训练代码模型

**来源**: ICSE 2024 | **作者**: Shuzheng Gao 等

## 摘要
预训练代码模型在代码智能任务中取得了显著进展，但下游任务中标注数据集通常规模有限，制约了模型性能。本文提出HINT方法，通过伪标签技术利用大规模无标签数据来改善预训练代码模型的微调效果。HINT包含两个核心模块：混合伪标签数据选择和噪声容忍训练。混合选择模块结合训练损失和基于检索的方法过滤低质量伪标签数据；噪声容忍训练模块通过对称交叉熵损失和一致性正则化进一步缓解伪标签噪声的影响。在代码摘要、缺陷检测和断言生成三个任务上的实验表明，HINT分别提升了最佳基线模型15.33%、16.50%和8.98%。

## 引言核心
- 预训练代码模型依赖有限的标注数据进行微调，数据规模不足制约性能
- 从开源网站爬取的数据集规模小且质量低（如仅6.8%的JavaScript代码有对应注释）
- 伪标签技术可利用无标签数据，但直接使用会引入大量噪声
- 仅依赖训练损失的数据选择策略不够鲁棒，可能错误评估伪标签质量
- 需要一种混合策略来有效筛选高质量伪标签数据并容忍残余噪声

## 方法概述
HINT框架分为三个阶段：首先在有标签数据上训练教师模型，用其为无标签数据生成伪标签。然后通过混合伪标签数据选择模块筛选高质量数据——该模块结合基于损失的选择（过滤高损失样本）和基于检索的选择（通过BM-25检索相似训练样本，比较伪标签与真实标签的相似度）。

在噪声容忍训练阶段，使用筛选后的伪标签数据训练学生模型，采用对称交叉熵损失函数增强对噪声的容忍度，并通过一致性正则化确保模型对原始代码和变换后代码的预测保持一致。整个过程可迭代多次，实现模型的自我提升。

## 关键实验发现
- RQ1（有效性）：HINT在三个任务上均显著提升预训练模型性能，UniXcoder在代码摘要、缺陷检测、断言生成上分别提升15.33%、16.50%、8.98%
- RQ2（模块贡献）：混合数据选择和噪声容忍训练两个模块均有独立贡献，组合使用效果最佳
- RQ3（通用性）：HINT可构建在CodeBERT、CodeT5、UniXcoder等多种预训练模型之上，均能一致提升性能

## 写作特征备注
- 标题结构：隐喻式标题（Learning in the Wild）+ 副标题说明具体任务
- 摘要是否有数字：是（15.33%、16.50%、8.98%提升）
- 是否有RQ：是（通过实验部分的研究问题组织）
- 是否有Motivating Example：是（Figure 1展示伪标签质量评估的动机示例）
- 贡献点数量：3

## 结论
HINT首次在代码智能任务的微调阶段以任务特定方式利用大规模无标签数据，通过混合数据选择和噪声容忍训练有效提升了预训练代码模型的性能，为数据稀缺场景下的代码智能研究提供了新思路。
