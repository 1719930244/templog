# Fight Fire with Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?
# 以火攻火：我们能在多大程度上信任ChatGPT处理源代码相关任务？

**来源**: TSE 2024 | **作者**: Xiao Yu 等

## 摘要
随着ChatGPT在软件开发中的广泛应用，验证其生成代码的质量变得至关重要。近期研究提出利用ChatGPT同时作为开发者和测试者进行多智能体协作开发，但未评估生成的测试报告在验证代码方面的有效性。本文对ChatGPT在代码生成、代码补全和程序修复三个任务上的自我验证能力进行了全面实证研究。研究发现：(1) ChatGPT经常错误地将其生成的错误代码判断为正确；(2) 存在自相矛盾的幻觉现象；(3) 引导性问题可提升自我验证能力；(4) 测试报告在漏洞检测方面有效，但对错误代码的解释大多不准确。

## 引言核心
- ChatGPT在代码生成、补全和修复方面展现出强大能力，但生成的代码可能存在质量问题或漏洞
- 多智能体协作方法让ChatGPT同时充当开发者和测试者，但未评估其自我验证的有效性
- 需要系统评估ChatGPT能否可靠地验证自己生成的代码
- 设计了三种自我验证提示策略：直接提问、引导性提问和测试报告
- 在代码生成、代码补全和程序修复三个任务上进行全面评估

## 方法概述
研究设计了三种自我验证提示策略，分别应用于三个代码相关任务。对于每个任务，首先让ChatGPT执行代码生成/补全/修复，然后使用三种提示策略进行自我验证：(1) 直接提问——直接询问代码是否正确/安全/修复成功；(2) 引导性提问——提出断言（如"代码未正确实现功能"）并询问ChatGPT是否同意；(3) 测试报告——要求ChatGPT生成测试报告来验证代码。

实验使用两个代码生成数据集（MBXP和HumanEval-X）、一个代码补全数据集（Pearce等人的CWE场景数据集）和两个程序修复数据集。代码正确性通过测试用例验证，漏洞通过CodeQL扫描和三位资深开发者人工审查确认（Fleiss' kappa = 0.81）。

## 关键实验发现
- RQ1（代码生成自我验证）：ChatGPT平均57%的代码生成成功率，但自我验证时平均39%的错误率——经常错误地认为错误代码是正确的；引导性提问可多检测25%的错误代码
- RQ2（代码补全自我验证）：73%的补全无漏洞，但25%的漏洞代码被错误判断为安全；引导性提问多识别69%的漏洞，测试报告多识别77%的漏洞
- RQ3（程序修复自我验证）：70%的修复成功率，但28%的失败修复被错误判断为成功；存在自相矛盾的幻觉——ChatGPT先认为修复成功，后又判断为失败
- 测试报告对错误代码和失败修复的解释大多不准确（平均75%）

## 写作特征备注
- 标题结构：成语/隐喻式标题（Fight Fire with Fire）+ 研究问题副标题
- 摘要是否有数字：是（39%、25%、28%错误率等）
- 是否有RQ：是（明确的RQ1-RQ3）
- 是否有Motivating Example：否（直接进入研究设计）
- 贡献点数量：2

## 结论
ChatGPT的自我验证存在显著的不准确性和自相矛盾的幻觉，表明在当前阶段人类专业判断在软件开发和评估中仍不可替代，ChatGPT应被视为辅助工具而非自主开发者和测试者。
