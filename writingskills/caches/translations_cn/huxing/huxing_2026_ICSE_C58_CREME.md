# CREME: Robustness Enhancement of Code LLMs via Layer-Aware Model Editing
# CREME：通过层感知模型编辑增强代码大语言模型的鲁棒性

**来源**: ICSE 2026 | **作者**: Shuhan Liu 等

## 摘要
大语言模型（LLM）在代码生成中展现了出色能力，但研究表明LLM对提示扰动高度敏感——措辞、语法或格式的微小修改可能显著降低生成代码的功能正确性。本文提出CREME（Code LLM Robustness Enhancement via Model Editing），一种通过定向参数更新增强LLM鲁棒性的新方法。CREME首先通过比较原始提示和扰动变体之间的隐藏状态来识别鲁棒性敏感层，然后在识别出的层上执行轻量级参数编辑以减少性能退化。在HumanEval和MBPP基准测试上的实验表明，CREME在扰动提示上将Pass@1准确率提升了63%，同时在干净输入上保持稳定性能（偏差在±1%以内）。

## 引言核心
- LLM对提示扰动（拼写错误、冗余表达、格式变化）高度敏感，微小变化可能导致完全不同的输出
- 现有鲁棒性增强方法分为输入级干预（如去噪、改写）和模型增强方法（如LoRA、RAG），但前者不修改模型内部鲁棒性，后者增加系统复杂度
- 知识编辑技术可实现高效的后训练更新，但现有方法主要针对事实知识，难以处理复杂的多句自然语言提示
- CREME仅需一对提示（原始+扰动）即可增强模型对特定类型扰动的鲁棒性
- 提出G-RIR评估指标，量化鲁棒性增强方法的泛化能力

## 方法概述
CREME包含两个主要组件。首先，通过层级因果干预策略进行关键层定位：对每个Transformer层，将扰动提示的隐藏状态替换为原始提示的对应隐藏状态，然后评估修复后的代码生成准确率，选择恢复改善最大的层作为关键层。其次，在识别出的关键层上执行表示对齐的模型编辑，通过轻量级参数更新使扰动提示的表示与原始提示对齐，同时保持模型在干净输入上的行为不变。

该方法的核心优势在于仅需单对提示即可完成编辑，不需要完整的重训练或额外的外部数据。通过因果追踪定位鲁棒性敏感层，实现了精准且高效的参数修改。

## 关键实验发现
- RQ1（有效性）：CREME在扰动提示上实现63%的Pass@1相对提升，显著优于Self-Denoising、LoRA Fine-Tuning、ROME和DINM四个基线
- RQ2（泛化性）：基于单个扰动实例的编辑可恢复该扰动类别中高达30%的整体代码生成准确率
- RQ3（层定位分析）：鲁棒性敏感层主要集中在网络的中间和深层，且位置因模型架构而异，呈现聚类模式
- RQ4（稳定性）：CREME在干净输入上的准确率偏差在±1%以内，保持了模型的原始性能

## 写作特征备注
- 标题结构：工具命名型（CREME: ...via...）
- 摘要是否有数字：是（63%、±1%、30%）
- 是否有RQ：是
- 是否有Motivating Example：是（CodeLlama-7b在HumanEval/49上的拼写错误示例）
- 贡献点数量：3

## 结论
CREME通过层感知的因果干预和轻量级参数编辑，有效增强了代码LLM对提示扰动的鲁棒性，同时揭示了鲁棒性敏感层在不同模型架构中的分布规律。
