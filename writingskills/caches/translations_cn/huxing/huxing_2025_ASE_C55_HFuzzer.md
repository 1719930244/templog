# HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-based Fuzzing
# HFuzzer：基于短语的模糊测试检测大语言模型的包幻觉

**来源**: ASE 2025 | **作者**: Yukai Zhao 等

## 摘要
大语言模型广泛用于代码生成，但面临包幻觉的关键安全风险——即LLM推荐不存在的包。这些幻觉可被利用于软件供应链攻击，恶意攻击者注册有害包。虽然已有针对自然语言生成中事实冲突幻觉的测试框架，但缺乏对包幻觉的研究。本文提出HFuzzer，一个基于短语的模糊测试框架，用于测试LLM的包幻觉。HFuzzer采用模糊测试技术，引导模型基于短语推断更广泛的合理信息，生成充足且多样的编码任务。从包信息或编码任务中提取短语以确保相关性。评估表明HFuzzer在所有目标模型上触发了包幻觉，比变异模糊测试框架多发现2.60倍的唯一幻觉包。测试GPT-4o时发现46个唯一幻觉包。

## 引言核心
- 包幻觉是LLM代码生成中的关键安全威胁，可被利用进行软件供应链攻击
- LLM代理（如Devin）能自动执行命令，进一步增加了包幻觉攻击的成功率
- 现有研究受限于数据集规模，无法覆盖广泛的代码生成场景
- 挑战1：如何覆盖尽可能多的代码生成场景，生成充足且多样的编码任务
- 挑战2：如何生成与代码相关的任务来测试包幻觉，避免非代码相关任务

## 方法概述
HFuzzer包含两个主要部分：短语提取和模糊测试循环。在短语提取阶段，HFuzzer将包信息形式化为短语组合（Object, Predicate, Complement），利用测试模型从包描述中提取短语构建种子池。例如，包"pre-commit"的描述被形式化为（pre-commit hooks, managing and maintaining, multi-language support）。

在模糊测试循环阶段，HFuzzer按照种子选择、任务生成、幻觉触发、幻觉评估、能量调整和种子池扩展的流程迭代。每轮从种子池中按权重随机选择三个短语组成种子，由测试模型生成编码任务，目标模型生成代码并推荐包，然后评估推荐包是否存在于包索引（如PyPI）中。根据幻觉评分调整相关短语的能量，引导未来选择朝向未充分探索的短语。对触发幻觉的任务提取新短语扩展种子池。

## 关键实验发现
- RQ1（有效性）：HFuzzer在所有目标模型上成功触发包幻觉，比GPTFUZZER-A平均多发现2.60倍唯一幻觉包
- RQ2（多样性）：HFuzzer生成的任务比GPTFUZZER-A更加多样
- RQ3（通用性）：使用9个不同模型作为测试和目标模型，HFuzzer在所有测试模型上均优于GPTFUZZER-A
- RQ4（GPT-4o分析）：发现46个唯一幻觉包，包幻觉不仅发生在代码生成中，也发生在环境配置辅助中

## 写作特征备注
- 标题结构：工具命名型（"HFuzzer" + 任务描述 + 技术手段）
- 摘要是否有数字：是（2.60倍、46等）
- 是否有RQ：否（通过挑战-解决方案结构引出）
- 是否有Motivating Example：是（Figure 1展示HTTP/2服务器代码生成中的包幻觉示例）
- 贡献点数量：3

## 结论
HFuzzer首次将模糊测试引入LLM包幻觉检测领域，通过基于短语的任务生成方法有效覆盖多样化的代码生成场景，在所有测试模型上均成功触发包幻觉并显著优于基线方法。
