# Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction
# 面向软件工程的联邦学习：代码克隆检测与缺陷预测案例研究

**来源**: TSE 2023 | **作者**: Yanming Yang 等

## 摘要
在各研究领域中，基于AI的学习模型在基准数据集上表现良好，但将学术成果转化为工业实践面临挑战：工业数据存在数据倾斜问题（标签分布倾斜和数量倾斜），且由于隐私政策难以获取。本文提出了基于联邦学习的框架ALMITY，旨在简化研究成果向实际应用的转化过程。ALMITY引入了一种创新的聚合策略，综合考虑数据规模、数据平衡度和少数类可学习性三个关键属性，在保护数据隐私的同时提升模型在倾斜数据分布上的性能。在代码克隆检测和缺陷预测两个SE任务上，ALMITY在所有类型的倾斜数据分布上均优于集中式训练方法和原始联邦学习方法。

## 引言核心
- 学术模型在基准数据集上表现好，但在工业数据上性能显著下降（超过30%）
- 工业数据存在数据倾斜问题：标签分布倾斜（如克隆代码仅占10-20%）和数量倾斜（大小公司数据量差异巨大）
- SE研究者因严格的隐私政策难以获取真实工业数据，无法了解工业开发者的实际需求
- 传统训练方法无法解决数据倾斜导致的模型性能下降问题
- 原始联邦学习的聚合算法仅考虑数据规模一个属性，无法处理倾斜数据集

## 方法概述
ALMITY基于联邦学习框架，包含中央服务器和多个客户端。与原始联邦学习类似，ALMITY仅共享模型更新（如梯度信息）和数据分布信息而非原始数据，保护数据隐私。其核心创新在于提出了一种新的参数聚合策略，综合考虑三个属性：数据平衡度（衡量数据集的标签分布均衡程度）、数据规模（衡量数据集大小）和少数类可学习性（衡量模型对少数类的学习能力）。

通过这三个属性的综合集成来优化模型参数，ALMITY能够有效处理复杂和倾斜的数据，减轻数据倾斜对模型训练的负面影响。实验在代码克隆检测和缺陷预测两个SE任务上进行，使用ML和DL两种模型类型，与集中式训练方法（CTM）和原始联邦学习（VFL）进行比较。

## 关键实验发现
- RQ1（有效性）：ALMITY在所有类型的倾斜数据分布上均优于CTM和VFL基线，在两个SE任务上均达到最高G-Mean性能
- RQ2（消融实验）：三个属性（数据平衡度、数据规模、少数类可学习性）均对聚合策略产生积极影响，每个属性在不同数据分布类型中发挥关键作用

## 写作特征备注
- 标题结构：主题:案例研究（Federated Learning for SE: A Case Study of ...）
- 摘要是否有数字：否（无具体数值，但有定性描述）
- 是否有RQ：是
- 是否有Motivating Example：是（Alice和Bob的工业场景故事 + 三个现实应用场景）
- 贡献点数量：4

## 结论
ALMITY是首个在SE任务中应用并增强联邦学习技术的工作，通过创新的三属性聚合策略有效弥合了学术研究与工业应用之间的鸿沟，在保护数据隐私的同时显著提升了模型在倾斜数据分布上的性能。
