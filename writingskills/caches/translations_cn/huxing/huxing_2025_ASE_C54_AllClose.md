# When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs
# 当AllClose失败时：深度学习程序的舍入误差估计

**来源**: ASE 2025 | **作者**: Qi Zhan 等

## 摘要
深度学习程序通过内核级优化、并行训练和低精度算术不断提升性能，这些优化提供了数学等价但实现不同的方案。浮点计算中的舍入误差可能导致这些实现的输出差异，当差异超过容差阈值时，开发者难以区分可接受的舍入误差和实现缺陷。本文提出RENDER方法，通过估计最大舍入误差来分类两种实现之间的数值误差。RENDER结合动态区间算术和舍入误差分析来计算可扩展且紧凑的输出界限。与最先进工具SATIRE和高精度重执行基线相比，RENDER至少多识别25%的误差，并实现19倍的平均加速。

## 引言核心
- 深度学习程序的多种优化实现（内核优化、分布式训练、低精度算术）在数学上等价但输出可能不同
- 开发者通常使用torch.allclose函数比较输出，但当allclose失败时难以判断是舍入误差还是实现缺陷
- 实际案例：Hugging Face Transformers中的梯度累积缺陷被误归因于舍入误差，持续三年才被修复
- 误差分类为两类：Type-I（可接受的舍入误差，可通过调整精度缓解）和Type-II（实现缺陷，需修复）
- 传统舍入误差估计方法直接应用于DL程序面临计算规模大和底层实现不透明的挑战

## 方法概述
RENDER基于三个关键思想估计浮点舍入误差。第一，结合区间算术和误差分析：采用快速区间算术方法估计每个操作输出张量的区间，对不透明操作（如矩阵乘法）结合误差分析与上下界，确保误差界限的可靠性。第二，动态分析：利用具体输入重新运行目标程序，在执行过程中估计每个张量的区间，避免对max、min和条件语句等操作的不必要过估计。第三，从神经网络到内核级界限：将整个神经网络的误差估计问题分解为一系列内核级估计，简化整体分析并使其可扩展到大型复杂DL程序。

RENDER基于Triton和PyTorch实现。给定目标程序和参考程序的输出差异，RENDER估计目标程序输出的上下界：如果参考输出落在界限内，则分类为Type-I（舍入误差）；否则分类为Type-II（实现缺陷）。

## 关键实验发现
- RQ1（分类准确性）：在20个内核级测试用例中（16个Type-I、4个Type-II），RENDER比SATIRE和高精度重执行基线分别多成功分类8个和5个案例
- RQ2（误差界限紧凑性）：在成功案例中，RENDER始终提供比SATIRE更紧凑的误差界限
- RQ3（效率）：RENDER相比SATIRE实现平均19倍加速
- RQ4（实际应用）：在7个真实神经网络问题中成功分析6个，提交5份反馈报告，2份已被开发者确认

## 写作特征备注
- 标题结构：场景引入型（"When AllClose Fails" + 具体研究任务描述）
- 摘要是否有数字：是（25%、19倍等）
- 是否有RQ：否（采用问题定义+解决方案的结构）
- 是否有Motivating Example：是（Figure 1展示allclose通过和失败的两个场景）
- 贡献点数量：3

## 结论
RENDER首次在深度学习程序上下文中对数值误差进行分类，通过结合动态区间算术和内核级误差分析，帮助开发者高效区分可接受的舍入误差和需要修复的实现缺陷。
