# CodeEditor: Learning to Edit Source Code with Pre-trained Models
# CodeEditor：基于预训练模型学习编辑源代码

**来源**: TOSEM 2023 | **作者**: Jia Li 等

## 摘要
开发者在软件开发过程中经常执行重复性的代码编辑活动（高达70%）。现有预训练代码编辑模型主要使用源自NLP领域的代码填充任务（如掩码语言建模）作为预训练任务，并非专为自动代码编辑设计。本文提出了一种专门针对代码编辑的新型预训练任务，并构建了预训练代码编辑模型CodeEditor。该方法收集大量真实代码片段作为ground truth，利用强大的生成器（CodeGPT）将其改写为变异版本，然后预训练CodeEditor将变异版本编辑回原始版本以学习编辑模式。在四个代码编辑数据集上，CodeEditor在微调设置下分别提升15%、25.5%、9.4%和26.6%，在少样本设置下甚至超越使用全部数据微调的基线，在零样本设置下正确编辑了1,113个程序。

## 引言核心
- 开发者每周花费超过6小时编辑源代码，大量编辑（70-100%）遵循重复模式
- 手动设计重复编辑模式既繁琐又容易出错
- 现有预训练代码编辑模型使用的代码填充任务源自NLP领域，非专为代码编辑设计
- 代码填充任务仅随机遮蔽并预测离散token，与真实代码编辑任务存在差距
- 需要一种更贴近真实代码编辑场景的预训练任务来提升模型性能和泛化能力

## 方法概述
CodeEditor的核心创新在于提出了一种专门针对代码编辑的预训练任务。具体而言，首先从开源社区（如GitHub）收集大量通过代码审查的程序作为ground truth，然后利用预训练语言模型CodeGPT作为生成器，将这些程序改写为自然但质量较低的变异版本。预训练阶段让CodeEditor学习将变异代码编辑回原始版本，从而学习多样化的编辑模式（如API更新、类型/对象变更、标识符重命名等）。

与代码填充任务相比，该预训练任务有两个优势：（1）任务更具挑战性，需要高层次的理解能力来定位劣质部分和强大的生成能力来产生更好的替代方案，从而提供更强的监督信号；（2）任务更接近真实代码编辑场景，赋予模型实际的代码编辑能力，增强泛化性。

## 关键实验发现
- RQ1（有效性）：在微调设置下，CodeEditor在四个数据集上分别超越SOTA基线15%、25.5%、9.4%和26.6%；在少样本设置下超越所有基线，甚至优于使用全部数据微调的基线
- RQ2（零样本能力）：在零样本设置下，CodeEditor正确编辑了1,113个程序，而SOTA基线无法工作

## 写作特征备注
- 标题结构：工具名:描述（CodeEditor: Learning to Edit Source Code with Pre-trained Models）
- 摘要是否有数字：是（70%、15%、25.5%、9.4%、26.6%、1,113个程序）
- 是否有RQ：是（通过三种设置评估）
- 是否有Motivating Example：是（Figure 1展示了两个真实代码编辑示例）
- 贡献点数量：3（新预训练任务、CodeEditor模型、三种设置的全面评估）

## 结论
CodeEditor通过提出专门针对代码编辑的预训练任务，显著提升了代码编辑模型的性能和泛化能力，在微调、少样本和零样本三种设置下均展现出优越的表现，证明了面向任务的预训练设计对代码编辑的重要性。
