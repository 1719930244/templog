# Chain-of-Thought in Neural Code Generation: From and For Lightweight Language Models
# 神经代码生成中的思维链：面向轻量级语言模型的探索

**来源**: TSE 2024 | **作者**: Xiang Chen 等

## 摘要
代码生成旨在根据自然语言描述自动生成代码片段。近年来，大型语言模型（LLM）在代码生成任务上取得了显著进展。然而，LLM的高计算成本限制了其在资源受限场景下的应用。本文研究了思维链（Chain-of-Thought, CoT）技术在轻量级语言模型上的代码生成效果。我们提出了COTTON框架，通过从LLM中提取CoT推理能力，将其迁移到轻量级模型中。具体而言，COTTON首先利用LLM生成带有CoT注释的代码，然后使用这些数据微调轻量级模型。实验在HumanEval和MBPP基准上进行，结果表明COTTON能显著提升轻量级模型的代码生成能力，在Pass@1指标上平均提升5%-10%。

## 引言核心
- 代码生成是软件工程中的基础任务，LLM（如GPT-4、CodeLlama）表现优异但计算成本高
- 现有轻量级模型缺乏推理能力，直接生成代码时容易出错
- CoT推理可以将复杂问题分解为步骤，但如何将其应用于轻量级代码模型尚未充分研究
- 核心insight：LLM生成的CoT推理过程可以作为"教学材料"来训练轻量级模型

## 方法概述
COTTON框架包含三个阶段：
1. **CoT数据收集**：利用LLM为编程题目生成带有逐步推理的代码解决方案
2. **数据过滤与增强**：过滤低质量CoT数据，通过多样化采样增强数据集
3. **轻量级模型微调**：使用收集的CoT数据对CodeT5+、CodeGen等轻量级模型进行微调

## 关键实验发现
- RQ1（有效性）：COTTON在HumanEval上将CodeT5+的Pass@1从15.2%提升至21.3%
- RQ2（消融）：CoT数据的质量比数量更重要，过滤步骤贡献最大
- RQ3（泛化性）：COTTON在不同规模的轻量级模型上均有效
- RQ4（效率）：微调后的轻量级模型推理速度比LLM快10-50倍

## 结论
本文提出COTTON框架，首次系统研究了CoT技术在轻量级代码生成模型上的应用。实验证明通过知识蒸馏的方式可以有效提升小模型的推理和代码生成能力。
