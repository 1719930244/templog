# Assessing and Improving Syntactic Adversarial Robustness of Pre-trained Models for Code Translation
# 评估和改进代码翻译预训练模型的语法对抗鲁棒性

**来源**: IST 2025 | **作者**: Xiang Chen 等

## 摘要
代码翻译（如Java→Python）的预训练模型在标准基准上表现良好，但对语法层面的对抗扰动敏感。本文系统评估了代码翻译模型的语法对抗鲁棒性，并提出改进方法。通过设计保持语义不变的语法变换（如变量重命名、代码风格变换），测试模型的鲁棒性，并通过对抗训练提升模型的抗扰动能力。

## 方法概述
1. **语法扰动设计**：设计多种保持语义的语法变换策略
2. **鲁棒性评估**：在扰动前后比较翻译质量
3. **对抗训练**：使用扰动数据增强训练集，提升模型鲁棒性
4. **多模型评估**：在CodeBERT、CodeT5、PLBART等模型上验证

## 关键发现
- 现有模型对语法扰动高度敏感，翻译质量下降显著
- 变量重命名是影响最大的扰动类型
- 对抗训练可有效提升鲁棒性，且不损害正常性能
