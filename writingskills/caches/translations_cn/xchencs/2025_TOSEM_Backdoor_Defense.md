# Defending Code Language Models against Backdoor Attacks with Deceptive Cross-Entropy Loss
# 基于欺骗性交叉熵损失防御代码语言模型后门攻击

**来源**: TOSEM 2025 | **作者**: Xiang Chen 等

## 摘要
代码语言模型（如CodeBERT、CodeT5）在代码智能任务中广泛应用，但容易受到后门攻击。攻击者可以在训练数据中植入触发器，使模型在遇到特定输入模式时产生恶意输出。本文提出了一种基于欺骗性交叉熵（Deceptive Cross-Entropy, DCE）损失的防御方法。DCE通过修改训练目标函数，使模型在学习正常任务的同时，降低对潜在触发器模式的敏感性。

## 引言核心
- 代码语言模型的供应链安全问题日益严重
- 后门攻击可以在不影响正常性能的情况下植入恶意行为
- 现有防御方法（如数据清洗、模型检测）在代码领域效果有限
- 核心insight：通过修改损失函数可以在训练阶段就抑制后门学习

## 方法概述
1. **威胁模型定义**：明确攻击者能力和防御者假设
2. **DCE损失设计**：在标准交叉熵基础上增加正则化项，惩罚模型对低频模式的过度拟合
3. **自适应阈值**：动态调整正则化强度，平衡正常性能和防御效果
4. **多任务适配**：将DCE扩展到代码摘要、缺陷检测、克隆检测等多个任务

## 关键实验发现
- RQ1：DCE在5种后门攻击下将攻击成功率从90%+降至10%以下，同时正常性能损失<2%
- RQ2：与现有防御方法（Fine-Pruning、NAD等）相比，DCE在防御效果和性能保持上均更优
- RQ3：消融实验证明正则化项和自适应阈值都是必要的
- RQ4：DCE对不同触发器类型（固定/动态/语法）均有效

## 结论
本文提出DCE防御方法，通过修改训练损失函数有效抵御代码语言模型的后门攻击，在防御效果和正常性能之间取得了良好平衡。
