# An Empirical Study of Adversarial Training in Code Comment Generation
# 代码注释生成中对抗训练的实证研究

**来源**: SEKE 2023 | **作者**: Xiang Chen 等

## 摘要
代码注释生成模型的鲁棒性是实际部署的关键。本文对对抗训练在代码注释生成中的效果进行了实证研究。通过设计多种代码扰动策略，评估对抗训练能否提升注释生成模型的鲁棒性。

## 方法概述
1. 设计代码级对抗扰动（变量重命名、死代码插入等）
2. 在多个注释生成模型上应用对抗训练
3. 评估对抗训练前后的鲁棒性变化

## 关键发现
- 对抗训练可以提升模型对代码扰动的鲁棒性
- 不同扰动类型对模型的影响程度不同
- 对抗训练在不损害正常性能的前提下提升了鲁棒性
