# How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective
# 好的方法名在神经代码生成中有多重要？模型鲁棒性视角

**来源**: TOSEM 2023 | **作者**: Xiang Chen 等

## 摘要
神经代码生成模型依赖自然语言描述和代码上下文来生成代码。方法名作为代码的重要语义信息，其质量可能影响代码生成效果。本文从模型鲁棒性角度研究方法名对神经代码生成的影响。通过系统的对抗性实验，我们发现现有模型对方法名的扰动高度敏感。

## 引言核心
- 代码生成模型在标准基准上表现良好，但鲁棒性未被充分研究
- 方法名是代码中最重要的标识符之一，承载关键语义信息
- 现有研究忽略了方法名质量对代码生成的影响
- 核心问题：如果方法名被修改（如缩写、拼写错误、语义偏移），模型表现会如何？

## 研究方法
1. **扰动策略设计**：设计多种方法名扰动策略（重命名、缩写、拼写错误、语义替换等）
2. **模型选择**：选取多个代表性代码生成模型（CodeBERT、CodeT5、GPT系列等）
3. **影响评估**：在扰动前后比较模型的代码生成质量
4. **防御策略探索**：研究数据增强等方法能否提升模型对方法名扰动的鲁棒性

## 关键实验发现
- 方法名扰动导致代码生成质量显著下降（Pass@1下降10-30%）
- 语义替换比随机替换的影响更大
- 大模型比小模型对方法名扰动更鲁棒，但仍然敏感
- 数据增强可以部分缓解鲁棒性问题

## 结论
方法名对神经代码生成至关重要。本文揭示了现有模型的鲁棒性缺陷，并提出了改进方向。
