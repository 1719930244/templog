Actionable Warning Is Not Enough: Recommending Valid
Actionable Warnings with Weak Supervision
Zhipeng Xue
The State Key Laboratory of
Blockchain and Data Security,
Zhejiang University
Hangzhou, China
zhipengxue@zju.edu.cn
Zhipeng Gao
Shanghai Institute for Advanced
Study, Zhejiang University
Shanghai, China
zhipeng.gao@zju.edu.cn
Tongtong Xu
Huawei
Hangzhou, China
xutongtong9@huawei.com
Xing Hu
The State Key Laboratory of
Blockchain and Data Security,
Zhejiang University
Hangzhou, China
xinghu@zju.edu.cn
Xin Xia‚àó
The State Key Laboratory of
Blockchain and Data Security,
Zhejiang University
Hangzhou, China
xin.xia@acm.org
Shanping Li
The State Key Laboratory of
Blockchain and Data Security,
Zhejiang University
Hangzhou, China
shan@zju.edu.cn
Abstract
The use of static analysis tools has gained increasing popularity
among developers in the last few years. However, the widespread
adoption of static analysis tools is hindered by their high false alarm
rates (up to 90%). Previous studies have introduced the concept of
actionable warnings and built machine-learning method to distin-
guish actionable warnings from false alarms. However, according to
our empirical observation, the current assumption used for action-
able warning(s) collection is rather shaky and inaccurate, leading to
a large number of invalid actionable warnings. To address this prob-
lem, in this study, we build the first large actionable warning dataset
by mining 68,274 reversions from Top-500 GitHub C repositories,
we then take one step further by assigning each actionable warning
a weak label regarding its likelihood of being a real bug. Following
that, we propose a two-stage framework calledACWRecommender
to automatically recommend the actionable warnings with high
probability to be real bugs (AWHB). Our approach warms up the pre-
trained model UniXcoder by identifying actionable warnings task
(coarse-grained detection stage) and rerank AWHB to the top by
weakly supervised learning (fine-grained reranking stage). Experi-
mental results show that our proposed model outperforms several
baselines by a large margin in terms of nDCG and MRR for AWHB
recommendation. Moreover, we ran our tool on 6 randomly selected
projects and manually checked the top-ranked warnings from 2,197
reported warnings, we reported top-10 recommended warnings to
developers, 27 of them were already confirmed by developers as
real bugs. Developers can quickly find real bugs among the massive
amount of reported warnings, which verifies the practical usage of
our tool.
‚àóCorresponding Author
This work is licensed under a Creative Commons Attribution 4.0 International License.
ICSE ‚Äô26, Rio de Janeiro, Brazil
¬©2026 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-2025-3/26/04
https://doi.org/10.1145/3744916.3773133
CCS Concepts
‚Ä¢Software and its engineering ‚Üí Software maintenance tools.
Keywords
Actionable warning recommendation, Static analysis, Weak super-
vision, Data mining
ACM Reference Format:
Zhipeng Xue, Zhipeng Gao, Tongtong Xu, Xing Hu, Xin Xia, and Shanping Li.
2026. Actionable Warning Is Not Enough: Recommending Valid Actionable
Warnings with Weak Supervision. In2026 IEEE/ACM 48th International
Conference on Software Engineering (ICSE ‚Äô26), April 12‚Äì18, 2026, Rio de
Janeiro, Brazil.ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/
3744916.3773133
1 Introduction
The static analysis tools have been utilized for a considerable period
of time [17, 70, 71]. These tools are widely used by software devel-
opers and companies to detect potential bugs and report warnings
in recent years [20, 28, 35, 59, 62, 76]. For example, Facebook has
developedInfer[ 19, 23], a static code analysis tool for checking
generic bug patterns (e.g, null pointer exceptions, memory leaks,
and race conditions) in their Android and iOS apps (including the
main Facebook, Whatsapp, Instagram app, and many others). Due
to the lightweight analysis and low computational cost, these static
analysis tools have gained popularity among developers.
In spite of the success of static analysis tools, their widespread
adoption in various software projects is hindered by two major
problems. First, a high false alarm rate is observed. The warnings
generated by static analysis tools have a very high false-positive
rate (e.g., range up to 90%) [32]. In other words, only a small fraction
of the reported warnings are real bugs and/or need to be acted on.
Second, developers often experience information overloading while
using static analysis tools. That is, even if the real bugs are reported,
developers can become flooded with too many generated warnings.
They may fail to filter out the false alarms and tend to get lost in
massive amounts of irrelevant information.
arXiv:2511.12229v1  [cs.SE]  15 Nov 2025
ICSE ‚Äô26, April 12‚Äì18, 2026, Rio de Janeiro, Brazil Zhipeng Xue, Zhipeng Gao, Tongtong Xu, Xing Hu, Xin Xia, and Shanping Li
To fill these gaps and help developers to better make use of static
analysis tools, previous researchers have introduced the concept of
actionable warnings, namely the warnings that need to be acted
on by developers [14, 33]. Particularly, warnings that are acted on
by developers are called actionable warnings. In practice, a warning
is identified as ‚Äúactionable‚Äù if and only if a warning is present in a
revision and disappears in a subsequent revision. More formally,
given a sequence of commits ùê∂=ùëê 1, ùëê2, . . . , ùëêùëõ, let ùëä(ùëñ) denote the
set of warnings reported by a static analysis tool on commit ùëêùëñ
(1 ‚â§ùëñ‚â§ùëõ) . A warning ùë§‚ààùëä(ùëñ) is defined asactionableif it disap-
pears in any subsequent commit between ùëêùëñ and ùëêùëõ. The software
engineering researchers have proposed different techniques for the
task of actionable warning identification (AWI) [40, 67, 77].
Nonetheless, two significant limitations exist within these stud-
ies: Firstly, according to our in-depth analysis,the current data
collection process of obtaining actionable warnings is inaccu-
rate and unreliable. In other words, a considerable proportion of
actionable warnings are invalid and not real bugs [16, 42]. The use
of such uncurated datasets can be a major threat when models are
trained with such data. Unfortunately, many automatic approaches
proposed thus far [29, 30, 44] were trained and evaluated on these
unreliable actionable warnings, without paying attention to the
overall quality of the dataset and the correctness of warning labels.
Secondly, regarding actionable warning identification, the existing
approaches commonly use machine learning (ML) techniques for
this task. These approaches train ML classifiers by using a set of
hand-crafted features to determine whether warnings are action-
able or not. These features are manually designed by human experts
and critically affect the model‚Äôs performance. The warning features
determination islaborious and error-prone and heavily relies
on the domain knowledge of the experts. Moreover, there is no
guarantee that these hand-crafted features are well-designed (dif-
ferent studies may design redundant features [30, 31, 38, 56]) and
helpful (features have little contribution to the warning labels [67]).
Therefore, the research problem we aim to tackle in this paper is:
Given the reported warnings, can we accurately recommend the
warnings that are more likely to be real bugs without resorting to
manually pre-defined warning features?
In this study, we aim to rankactionable warningsproduced
by static analysis tools (InferandFlawfinderin this study) and
recommend theActionableWarning withHigh probability to be
realBug (A WHB). To be more specific, we build the first large
actionable warnings dataset under weak supervision and propose a
two-stage framework, namedACWRecommender(ACtionable
WarningRecommender), to automate this task. Our data col-
lection involves two steps. First, we collect actionable warnings
from the Top 500 popular C projects on GitHub, including 1,889
actionable warnings and 39,052 false alarms. Second, to identify
real bugs from actionable warnings, we propose a weak supervision
label strategy where each actionable warning is assigned a weak
label using our semantic and structural matching rules. The label
estimates the likelihood of the actionable warning being a real bug.
To recommend AWHB,ACWRecommenderis mainly divided into
two stages, including a coarse-grained warm-up stage and a fine-
grained reranking stage. In the coarse-grained detection stage, an
actionable warnings dataset is used to warm-up a neural network.
In the fine-grained reranking stage, we further fine-tune the model
to rank the AWHB to the top by weakly supervised learning [48, 49].
To evaluate the effectiveness of our weak supervision label strat-
egy andACWRecommender, we manually check the label accuracy
and conduct extensive experiments on the AWHB recommendation
task. By comparing with several baselines, the superiority of our
proposed model is demonstrated. The experimental results show
that: 1) According to our manual validation, 79.5% of AWHBs cor-
rectly identified real bugs, while only 19.5% of actionable warnings
were true positives that revealed actual issues. 2) Regarding the
AWHB recommendation task, our reranker performs better than
its three baselines in terms of nDCG and MRR; 3) We further con-
ducted an in-the-wild evaluation, and we report top-10 actionable
warnings recommended by our tool to the developers of 6 popular
Github projects, 27 of them have been confirmed by developers as
real bugs, which further justifies the practical usage of our approach.
In summary, this work makes the following contributions:
1)We build a large dataset for checking static analysis tools‚Äô action-
able warnings from popular GitHub C repositories, which contains
1,889 actionable warnings and 39,052 false alarms generated by
InferandFlawfinder. Then we propose a weak supervision label
strategy to identifyActionableWarnings withHigh probability to
be realBugs (A WHB). Our manual verification reveals that 81% of
AWHBs are real bugs.
2)We propose a novel two-stage model,ACWRecommenderto
automate the AWHB recommendation task.ACWRecommender
fine-tuned the large pre-train model UniXcoder with text and code
features, avoiding the laborious and error-prone process of design-
ing warning features manually. This work builds on our preliminary
demo tool [69] by extending it into a two-stage modeling frame-
work and conducting a comprehensive evaluation to validate its
effectiveness and practical value.
3)We extensively evaluate ourACWRecommenderwith several
baseline methods. Evaluation results show that our model can sig-
nificantly outperform the baselines in AWHB recommendation.
Moreover, we have conducted an in-the-wild evaluation with 6
GitHub projects, we submitted the top-10 reported warnings to the
developers, and 27 of them have been confirmed by developers as
real bugs.
4)We have released our replication package [ 8], including the
dataset and the source code ofACWRecommender. As the first
attempt for the AWHB recommendation, we hope our research
lays a good foundation for follow-up works and facilitates other
researchers and practitioners to verify their ideas.
2 Motivation
In this section, we first show several motivating examples of ac-
tionable warnings from real-world software projects.
Due to the high false alarm rate of static analysis tools, software
engineering researchers have proposed pipelines to collect action-
able warnings [14, 33, 64], namely warnings that need to be acted
on by developers. Upon investigation of these actionable warn-
ings, we have observed thatactionable warnings collected by
the current pipeline are inaccurate and may not necessarily
represent real bugs. This observation is also consistent with the
latest empirical findings [36]. The underlying reason is the current
pipeline regards warnings that exist in one revision and disappear in
Actionable Warning Is Not Enough: Recommending Valid Actionable Warnings with Weak Supervision ICSE ‚Äô26, April 12‚Äì18, 2026, Rio de Janeiro, Brazil
Table 1: The Examples of Actionable Warning-fix Commits
EX.1: Repo/Commit:open62541/d52786e [6]
367 static UA_StatusCode
UA_NodeMap_replaceNode(UA_Node *node) {
...
373 - UA_NodeMapSlot *slot = findOccupiedSlot(
- ns, &node->nodeId);
+ UA_NodeMapSlot *slot = findOccupiedSlot(
+ ns, &node->head.nodeId);
374 if(!slot)){
376 return UA_STATUSCODE_BADNODEID;}
380 UA_NodeMapEntry *oldEntry = slot->entry;
Commit Message:refactor(server): Use a union to avoid cast-
ing of node classes
Warning Type:Null Dereference
Warning Qualifier:pointer ‚Äòslot‚Äò last assigned on line 373
could be null and is dereferenced at line 380
EX.2: Repo/Commit:libevhtp/d13b72b [5]
3651 fd = socket(sa->sa_family, SOCK_STREAM, 0);
...
+ if (fd != -1)
+ evutil_closesocket(fd);
3673 return evhtp_accept_socket(htp, fd, backlog);
3674 }
Commit Message:FIX: Socket leakage on error #6.
Cleanup open file descriptors when bind_sockaddr fails.
Warning Type:Resource Leak
Warning Qualifier:Resource acquired to ‚Äòfd‚Äò by call to
‚Äòsocket()‚Äò at line 3651 is not released after line 3673.
later revisions as actionable warnings.However, this assumption
is rather shaky because the disappearance of such warnings
can be caused by a non-relevant fix/commit, leading to the
introduction of invalid actionable warnings. Table 1 demonstrates
two actionable warnings, an invalid actionable warning (Ex.1) and
a real bug warning addressed by developers (Ex.2).
Ex.1 shows an example of invalid actionable warnings.Inferre-
ported aNull Deferencewarning on line 373 because slot could
be null and dereferenced. However, this warning is invalid because
there is a null-checker for slot, and it will never be dereferenced
if it is null. This warning disappeared in a non-relevant commit
and was mistakenly extracted as an actionable warning. In contrast,
Ex.2 shows a genuine bug warning (Resource Leakat line 3651)
reported byInfer. To obtain a more accurate actionable warning
dataset, it is necessary to determine whether the given actionable
warning is invalid (i.e., Ex.1) or a genuine bug warning (i.e., Ex.2).
Upon analyzing the ‚Äúdisappeared revision‚Äù of the invalid actionable
warning and the genuine bug warning, we deduce that the genuine
bug warning can be correctly identified by considering two key
factors from the fix revision: semantic factor (e.g., commit mes-
sage) and structural factor (e.g., code change context). The commit
message conveys the semantic intention of the commit [26, 47, 65],
while the code change conveys the syntactic structural informa-
tion regarding the behavior of the commit [ 56, 66]. For example,
the commit message of the genuine bug warning (Ex.2) validates
the warning type (e.g., socket leakage), and the code change is a
common code pattern for patching resource leakage, suggesting
a high probability of this warning being related to a real bug. On
the contrary, for the invalid actionable warning (Ex.1), the commit
message and code change of its disappeared revision have no corre-
lation with the reportedNull Deferencewarning, which implies
the likelihood of being a real bug of this warning is relatively low.
Guided by the motivating example, we propose a weak super-
vision labeling strategy including semantic (commit message) and
syntactic (code change pattern) matching rules to distinguish AWHB
from noisy actionable warnings, and use these labels to fine-tune
the pre-trained model.
3 Approach
The overall framework is illustrated in Fig. 1. We present details of
our approach design as follows.
3.1 Actionable Warnings Collection
The goal of this step is to collect all the actionable warnings from a
project and identify potential bug-fix revisions for each actionable
warning. A commonly used method is to run static analysis tools on
the compiled code of each revision and generate a list of warnings
for each revision [45, 46]. Then for each warning, check whether it
is closed in later revisions (label as actionable) or presented until
the last revision (label as a false alarm). However, the previous
method can be time-consuming and resource-intensive, especially
for large projects with a long history of revisions.
In this study, we propose a graph-based binary search algo-
rithm to efficiently identify actionable warnings and their corre-
sponding bug-fix revisions, while skipping irrelevant commits dur-
ing the search process. Our graph-based binary search algorithm
includes two parts: graph linearization and linear binary
search. Considering the real-world git histories often contain
branches and merges and are organized in graph structures, the
graph linearizationis responsible for converting a git commit
graph into a series of linear git histories. Following that, thelinear
binary search algorithm analyzes each linear git flow to iden-
tify actionable warnings and their corresponding bug-fix revisions
within this linear git history.
The graph lineariztion algorithm takes a git commit history
graph ùê∫ as input, and outputs all possible linear commit histories
within ùê∫. Each node in ùê∫ represents a specific software reversion,
while each edge represents a git commit connecting the previous
reversion and its subsequent reversion. Fig. 2 illustrates an example
of a Git commit graph where several reported warnings (marked as
A, B, C, and D) were fixed and its linear commit histories extracted
by our graph linearization algorithm. We definestart nodesas
nodes without parent nodes or nodes with more than one child
node (such as node 1, node 2, node 4), andend nodesas nodes
without child nodes (such as node 11). To perform the linearization,
we first remove all the merge commits (e.g., edges marked with
gray color) to avoid misleading results, such as falsely attributing a
fix to the current branch when it actually originated from another
branch via a merge. In this context, all the nodes before a merge
commit becomeend nodes(such as node 8, node 9 and node 7), and
all the nodes after a merge commit becomestart nodes(such as
node 10). We then obtain all possible linear git commit histories by
tracking from astart node(including node 1, node 2, node 4, and
node 10) until reaching anyend nodes(including node 6, node 7,
node 8 and node 11). As illustrated in Fig. 2, the git commit graph