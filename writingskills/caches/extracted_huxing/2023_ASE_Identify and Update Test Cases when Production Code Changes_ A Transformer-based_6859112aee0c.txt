Identify and Update Test Cases when Production
Code Changes: A Transformer-based Approach
Xing Hu∗, Zhuang Liu∗, Xin Xia†§, Zhongxin Liu†, Tongtong Xu‡, Xiaohu Y ang†
∗School of Software Technology, Zhejiang University, Ningbo, China
†College of Computer Science and Technology, Zhejiang University, Hangzhou, China
‡Software Engineering Application Technology Lab, Huawei, Hangzhou, China
{xinghu,liuzhuang,liuzx,yangxh}@zju.edu.cn, xin.xia@acm.org,xutongtong9@huawei.com
Abstract—Software testing is one of the most essential parts of
the software lifecycle and requires a substantial amount of time
and effort. During the software evolution, test cases should co-
evolve with the production code. However, the co-evolution of test
cases often fails due to tight project schedules and other reasons.
Obsolete test cases improve the cost of software maintenance
and may fail to reveal faults and even lead to future bugs.
Therefore, it is essential to detect and update these obsolete test
cases in time. In this paper, we propose a novel approachCEPROT
(Co-Evolution of Production-Test Code) to identify outdated test
cases and update them automatically according to changes in the
production code.CEPROT consists of two stages, i.e., obsolete test
identiﬁcation and updating. Speciﬁcally, given a production code
change and a corresponding test case, CEPROT ﬁrst identiﬁes
whether the test case should be updated. If the test is identiﬁed
as obsolete, CEPROT will update it to a new version of test case.
To evaluate the effectiveness of the two stages, we construct
two datasets. Our dataset focuses on method-level production
code changes and updates on their obsolete test cases. The
experimental results show that CEPROT can effectively identify
obsolete test cases with precision and recall of 98.3% and 90.0%,
respectively. In addition, test cases generated by CEPROT are
identical to the ground truth for 12.3% of samples that are
identiﬁed as obsolete by CEPROT. We also conduct dynamic
evaluation and human evaluation to measure the effectiveness
of the updated test cases by CEPROT. 48.0% of updated test
cases can be compiled and the average coverage of updated cases
is 34.2% which achieves 89% coverage improvement over the
obsolete tests. We believe that this study can motivate the co-
evolution of production and test code.
Index Terms—Test code maintenance, Mining Software Repos-
itories, Software Evolution
I. I NTRODUCTION
Software testing is generally considered as one of the most
crucial parts of the software development lifecycle [1], [2]. It
helps to identify potential faults and ensure software system
quality [3]. Generally, the source code continuously changes to
satisfy new requirements or cope with possible issues during
the software evolution [4]. To ensure the software quality,
the corresponding test cases should co-evolve alongside the
changed production code. Unfortunately, the co-evolution of
the production code and test code is often missing during the
software evolution due to the lack of time to maintain tests
or enough knowledge to identify whether tests need to be
updated [5]. To illustrate the inﬂuence of the obsolete test
§Corresponding author
/g3/g5
/g3/g6 public static String apiKey;
/g3/g7 public static String apiBase = "https://api.conekta.io";
/g3/g8 /g2 public static String apiVersion = "1.1.0";
/g3/g9 /g2 public static final String VERSION = "2.0.4";
/g3/g8 /g1 public static String apiVersion = "2.0.0";
/g3/g9 /g1 public static finalString VERSION = "2.1.0";
/g3/g10 public static String locale = "es";
/g5/g3 public void testSuccsessfulPrevious() throws JSONException, Error, ErrorList{
/g5/g4/g1 setApiVersion("2.0.0");
/g5/g5 Order last = (Order) list.get(0);
/g5/g6 JSONObject paginateParams = new JSONObject("{ 'limit': 10 }");
/g5/g7 ConektaList lastWindow = Order.where(paginateParams);
/g5/g16/g15/g9/g19/g8/g18/g12/g15/g14 /g2/g15/g9/g10 /g8/g15/g13/g13/g12/g18/g18/g10/g9 /g15/g14/g1/g23/g28/g1/g3/g10/g7/g1/g24/g22/g23/g29 /g26/g27/g27/g25/g9/g9/g23
/g6/g10/g17/g18 /g2/g15/g9/g10 /g8/g15/g13/g13/g12/g18/g18/g10/g9 /g15/g14/g1/g23/g30/g1/g4/g8/g18/g1/g24/g22/g23/g31 /g28/g22/g11/g22/g7/g31/g11
/g15/g14/g7/g2/g9/g13/g2/g7/g13/g12/g8/g11/g16/g6/g2/g3/g13/g12/g8/g11/g16/g6/g1/g10/g6/g17/g6
/g16/g8/g15/g16/g2/g9/g13/g2/g7/g13/g12/g8/g11/g16/g6/g2/g3/g13/g12/g8/g11/g16/g6/g4/g9/g15/g16/g5/g8/g15/g16/g1/g10/g6/g17/g6
Fig. 1. An example with obsolete test code.
cases, we show an example of project Conekta [6] in Figure
1. We can ﬁnd that the API version in the production code was
updated to 2.0.0 on 16 Feb 2017. However, it was only on 18
Oct 2019, the API version used in the corresponding test cases
was set to 2.0.0. Although the production code passed the test
and did not report failures, the new version APIs were never
tested during this period and might fail to reveal faults in the
production code. Just as the description in the test updating
commit,“The java library Junit test needed to be ﬁxed. Many
of the tests where failing due to an encapsulating error with
the method SetApiVersion. Also, other minor bugs where
ﬁxed regarding outdated references in the test”, and many bugs
may be introduced from obsolete test cases.
Therefore, many techniques are proposed to mine and
analyze the production and test code co-evolution rules and
patterns [7], [8], [5], [4]. For example, Zaidman et al. [7]
mined the data from version control systems to study the
co-evolution of production and test code. Some studies use
association rule mining techniques to generate co-evolution
patterns [4], [9]. Recently, Wang et al. [8] conducted an
empirical study to understand the practice of production-
test co-evolution. Then, they proposed an approach named
SITAR to facilitate the co-evolution of production and test
code by extracting features and leveraging machine-learning
techniques. According to their ﬁndings, updating existing test
code with the production code changes is signiﬁcantly more
frequent than other co-evolution types, e.g., adding/deleting
test code. However, their approach SITAR performed worst on
predicting whether existing test code should be updated with
1111
2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)
2643-1572/23/$31.00 ©2023 IEEE
DOI 10.1109/ASE56229.2023.00165
2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE) | 979-8-3503-2996-4/23/$31.00 ©2023 IEEE | DOI: 10.1109/ASE56229.2023.00165
Authorized licensed use limited to: Zhejiang University. Downloaded on May 28,2025 at 06:07:02 UTC from IEEE Xplore.  Restrictions apply. 
the production code changes than other types. Besides, the test
co-evolution is a difﬁcult task since even minor changes in the
production code can signiﬁcantly affect test code [10].
Inspired by their study, if existing test cases that need to be
updated can be automatically identiﬁed and co-evolved, it is
possible to reduce and even avoid the introduction of obsolete
test cases. Different from Wang et al. [8] that only propose to
identify obsolete test cases, in this paper, we further propose
updating the identiﬁed obsolete test cases.
We propose a novel approach named CEPROT to automate
the task, i.e., co-evolution of the production and test code
(shorted as production-test co-evolution task in the rest of this
paper). It includes two stages: CEPROT identiﬁes whether a
test case should be updated while the production code changes;
 it updates the test case according to the production code
changes simultaneously. However, the co-evolution task of
identifying and updating a test case is non-trivial. Existing
techniques usually deﬁne heuristic rules and extract features
manually to associate the production and test code changes [4].
It is time-consuming and labor-intensive to construct rules and
features. Moreover, there is a lack of effort to combine the
detection and updating of obsolete test cases as a whole and
perform automatic end-to-end production-test co-evolution.
To build a more effective tool that helps developers co-
evolve production code and test code, we propose to learn
from code changes of production code and update existing test
code. However, making such a tool is difﬁcult with respect to
the following challenges:
• Representing production code changes. Identifying and
updating obsolete test cases should understand production
code changes. Code changes include two versions of pro-
duction code that consist of a sequence of code tokens.
Each position of the code token has its corresponding edit
action, such as, “add”, “delete”, and “replace”. Therefore,
we should learn ﬁne-grained code changes from edit actions
to determine whether the corresponding test should be
updated and how to update.
• Identifying and updating obsolete test based on code
changes. In this study, we should learn from two versions
of production code, code change edits, and the existing
test to resolve the co-evolution of the production-test code
task. This task includes two stages, the obsolete test cases
identiﬁcation in stage 1 and updating them in stage 2. We
need to capture semantic correlations among code changes
and test cases to identify whether they are obsolete or not.
Considering stage 2, we need to update obsolete tests for
production code changes. Thus, we should learn where and
how to update them during the obsolete test updating stage.
To address the above challenges, we ﬁrst construct edit
sequences from two versions of the production code. The
edit sequence consists of tokens of the original version, new
version production code, and the edit action in a speciﬁc token
position. Then, we leverage the pre-trained encoder-decoder
Transformer model CodeT5 [11] that has shown remarkable
performance on learning from source code and generating code
to learn the semantic correlations to identify and update the
obsolete test cases. Transformer leverages the self-attention
techniques [12] that can learn ﬁne-grained correlations among
inputs. We ﬁne-tune the model on the identiﬁcation and up-
dating stages, respectively. In the online application, CEPROT
combines the two stages. To build and evaluate our model,
we build two datasets, one for method-level production-test
co-evolution identiﬁcation, and the other one used to update
the obsolete test cases. We compare C EPROT with different
baselines for the two tasks. Evaluation results show that: 1)
CEPROT outperforms its three baselines in the production-test
co-evolution identiﬁcation task in terms of Precision, Recall,
and F1-score. 2) C EPROT performs better than its two base-
lines in terms of Accuracy and CodeBLEU [13] by substantial
margins in the updating stage. The experimental results show
that CEPROT can help developers better understand where and
how to perform production-test co-evolution.
Except for static evaluation, we also conduct dynamic evalu-
ation on the CEPROT updated test cases. We build ﬁve popular
Java projects and execute updated test cases. The experimental
results show that 48.0% generated test cases by our approach
CEPROT can be compiled and and the average coverage
of updated cases is 34.2% which achieves 89% coverage
improvement over the obsolete tests. To explore the quality
of generated test cases from the developers’ perspective, we
conduct a human evaluation. Each practitioner is asked to
evaluate the updated test cases from two aspects, the quality of
the updated test cases and whether the updating is co-evolved
with production code changes. Experiments show that our
approach can generate high-quality test cases that co-evolve
with production code.
To summarize, our work makes the following contributions:
• We propose a novel two-stage approach, i.e., C EPROT,t o
automatically identify obsolete test cases and update them
for production code changes. It can effectively maintain the
co-evolution of production-test code on method level.
• We construct two datasets to identify and update obsolete
test cases for the production code changes. We conduct
extensive experiments on the dataset. C EPROT is shown
to outperform baselines in both two tasks. In addition,
it outperforms baselines by combining two stages by a
substantial margin.
• We provide our replication package [14] to help researchers
and practitioners to repeat our work and verify their studies.
II. B ACKGROUND
In this section, we brieﬂy introduce the task deﬁnitions of
the two stages of C EPROT and its usage scenarios. Then, we
illustrate the details of code change representation and CodeT5
that we exploit in this paper.
A. Task Deﬁnition
This work aims to identify and update obsolete test cases
given code changes at method level. A code change contains
two versions of production code, namely,x andx′. Similarly,
their associated test cases have two versions, namely,t andt′.
The obsolete test identiﬁcation task can be formulated as:
1112
Authorized licensed use limited to: Zhejiang University. Downloaded on May 28,2025 at 06:07:02 UTC from IEEE Xplore.  Restrictions apply. 
Identify(x,x′,t)=
{1i f t̸=t′
0 otherwise (1)
If t̸=t′,C EPROT will update the obsolete test case t:
Update(x,x′,t)= t′ (2)
We refer x, x′, t and t′ as original method, updated
method, original test, and updated test in the following parts
of our paper. Note that the updated test t′ is unknown before
identifying and updating in the practical application.
B. Usage Scenarios
In this paper, our tool aims to co-evolve the production-
test code at method-level. It consists of two stages, i.e., an
obsolete test identiﬁcation stage and an obsolete test updating
stage. The typical usage scenario of our tool is to provide test
updating suggestions when a developer makes production code
changes. Consider Alice is a developer in a large project team.
Daily, she performs the development and makes some changes.
Without our tool, she ignores to check whether the test cases
for the changed production code need to be updated. Further,
the obsolete test would not be updated due to her neglect. The
obsolete test cases may fail to test the corresponding code
changes and might even introduce bugs.
However, with our tool, there are several usage scenarios for
Alice while committing the production code change: (1) The
original test fails. In this scenario, Alice can realize from the
failure that the test case is out of date and should be updated
without our tool. However, our tool can accurately remind
her whether the original test case needs to be updated before
compiling and running. It can reduce her time waiting for
compilation and test results and avoid Alice from switching
the development context. Besides, our tool can generate a new
test case and reduce her edits on updating. (2) The original
test passes but becomes inadequate for quality assurance on
the new production code. With our tool, it can automatically
check whether the test needs to be updated. If the answer
is yes, CEPROT will update it subsequently. In summary, with
the help of our tool, Alice can successfully identify and update
obsolete test cases with fewer efforts, which can increase the
maintenance of the system and decrease the likelihood of
introducing bugs from production code changes.
C. Code Change Representation
To better represent ﬁne-grained production code changes,
we follow existing studies [15], [16] to construct code edits.
The code edit is represented as e = {xi
ai
→ x′
i}N
i=1 where
xi and x′
i are the token of original version and new version
production methods in the position of i, respectively. ai
indicates the edit action that converts xi into x′
i. There are
four types of edit actions, i.e., insert, delete, equal, and replace.
To get the code change representation, we ﬁrst tokenize the
original method and the modiﬁed method into sequences of
code tokens, and use them to construct the edit sequence. We
compute word-level alignment to get an edit triple in position
i, i.e., ⟨xi,x′
i,ai⟩. Finally, these edit triples form the edit
sequencee for a production code change. For example, the edit
sequencee for x: l.push(1)→ x′: l.pop() is e ={<l, l,
equal>, <., ., equal>, <push, pop, replace>, <(, (, equal>,
<1, ∅, delete>, <), ), equal>}.
D. CodeT5
In this paper, the identiﬁcation task and updating task can be
formulated as binary classiﬁcation and sequence-to-sequence
learning problems, respectively. In recent years, CodeT5 has
shown outstanding ability in code learning and generation
tasks, such as code clone detection and code completion.
In this paper, we leverage the Transformer-based model
CodeT5 [11] for modeling the production code and test cases,
and identifying and generating the updated test cases. CodeT5
is a uniﬁed pre-trained encoder-decoder Transformer model.
Different from CodeBERT [17] which relies on encoder pre-
training, or GPT [18] which relies on decoder pre-training,
CodeT5 uses an encoder-decoder architecture. Existing studies
show that the CodeT5 has achieved effective results in code-
related tasks, such as code generation and defect detection.
Thus, we exploit the CodeT5 to initialize our model and
ﬁnetune it on the two tasks.
III. A PPROACH
In this section, we ﬁrst introduce the overall framework of
CEPROT, then we describe the details of the main modules in
CEPROT including the outdated test identiﬁer and updater.
A. Overall Framework
The goal of C EPROT is to automate the production-test
co-evolution task. Figure 2 shows the overall framework of
CEPROT, which consists of three phases, i.e., input construc-
tion, model training, and online production-test co-evolution
application.I nt h e input construction phase, we convert the
input tokens into embeddings before feeding them into the
neural network. The model training phase consists of two
stages, i.e., outdated test identiﬁcation and outdated test up-
dating. In the outdated test identiﬁcation stage, we train a
neural network classiﬁer to identify outdated tests that are
needed to be updated. In the outdated test updatingstage, we
train the updater model to generate new test cases. Different
from the identiﬁcation stage, the updating stage only uses the
positive samples for training and considers the new test cases
as ground truth to be generated. In theapplicationphase, given
a code change (with two versions of production code and edit
sequence) and its associated old test, C EPROT ﬁrst leverages
the trained identiﬁer to predict whether the old test case needs
to be updated. If the answer is yes, the trained updater will
be used to generate a new test to replace the old one. We
elaborate on the details of each phase as follows:
B. Input Construction
The input of the model includes an original production
methodx, an updated production methodx′, and an original
testt. As shown in Figure 2, for each code segment, we ﬁrst
tokenize it into a sequence of tokens, i.e., x = {x1,...,xm},
1113
Authorized licensed use limited to: Zhejiang University. Downloaded on May 28,2025 at 06:07:02 UTC from IEEE Xplore.  Restrictions apply.