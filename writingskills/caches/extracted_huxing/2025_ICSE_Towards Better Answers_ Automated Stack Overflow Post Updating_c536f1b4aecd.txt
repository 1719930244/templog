Towards Better Answers: Automated Stack
Overflow Post Updating
Yubo Mai
Zhejiang University
Hangzhou, China
12021077@zju.edu.cn
Zhipeng Gao *
Shanghai Institute for Advanced Study of Zhejiang University
Shanghai, China
zhipeng.gao@zju.edu.cn
Haoye Wang
Hangzhou City University
Hangzhou, China
wanghaoye@hzcu.edu.cn
Tingting Bi
The University of Western Australia
Perth, Australia
tingting.bi@uwa.edu.au
Xing Hu
Zhejiang University
Hangzhou, China
xinghu@zju.edu.cn
Xin Xia
Zhejiang University
Hangzhou, China
xin.xia@acm.org
Jianling Sun
Zhejiang University
Hangzhou, China
sunjl@zju.edu.cn
Abstract—Utilizing code snippets on Stack Overflow (SO)
is a common practice among developers for problem-solving.
Although SO code snippets serve as valuable resources, it is
important to acknowledge their imperfections, reusing problem-
atic code snippets can lead to the introduction of suboptimal or
buggy code into software projects. SO comments often point out
weaknesses of a post and provide valuable insights to improve the
quality of answers, while SO comments are usually missed and/or
ignored, leaving these problematic code snippets untouched. In
this work, we first investigate the task of automatic SO posts
updating based on their associated comments. We introduce
a novel framework, named S OUP (Stack O verflow U pdator
for P ost) for this task. S OUP addresses two key tasks: Valid
Comment-Edit Prediction (VCP) and Automatic Post Updating
(APU). We fine-tuned a large language model, CodeLlama, using
low-rank adaptation techniques to complete the VCP task, and
constructed a dataset containing 78k valid comment-edit pairs
for the APU task. Subsequently, we tested the performance of
multiple large language models on the APU task. Extensive
experimental results show the promising performance of our
model over a set of benchmarks. Moreover, we also perform
an in-the-wild evaluation on Stack Overflow, we submitted 50
edits generated by our approach to Stack Overflow posts and
21 of them have been verified and accepted by SO maintainers,
further proving the practical value of S OUP.
Index Terms —Stack Overflow, Large Language Models, Post
Updating, Data Quality
I. I NTRODUCTION
As one of the most popular programming Q&A communi-
ties today, Stack Overflow (SO) offers a wealth of knowledge
for solving various programming issues, which is scattered
throughout its question and answer posts [1], [2]. However,
not all SO posts are “perfect”, many code snippets in the posts
are suboptimal (e.g., needing code simplification or extension),
problematic (e.g., using obsolete APIs or libraries), or even
buggy (e.g., security flaws) [3]. Reusing these code snippets
can mislead answer seekers and induce potential problems
and/or bugs into their working code base, decreasing software
quality and maintainability.
* This is the corresponding author
Question Post : Can you find all classes in a package using reflection? (649 votes)Answer Post : Without using any extra libraries:……URL unpackage = cl.getResource(pack) ;DataInputStream dis = new DataInputStream((InputStream) upackage.getContent());String line = null;while ((line = dis.readLine()) != null) { ……Comment1: I get a null when using this code. Seems to only work if your jar is an executable (Nov 2016)Comment2: if you obtained the package name fromString pack = getPackage().getName(); , then you have to addpack = pack.replaceAll(“[.]”, “/”);(May, 2019)
Fig. 1. Stack Overflow Post Example
Fortunately, SO comments provide useful information to
enhance the associated answers from a diverse range of
perspectives, such as pointing out weaknesses and suggesting
improvements. However, these SO comments can be easily
overlooked or ignored (in contrast to answers), therefore,
most comments are rarely integrated back into their associated
answers [3], [4], [5], [6]. Fig. 1 illustrates such an example,
the most recent edits of this answer occurred in 2014, all
subsequent comments (e.g., comment 1 & 2) were overlooked
and never integrated into answers. Moreover, since SO only
displayed five comments to users, these newly posted com-
ments can be hidden by SO and never be noticed.
Comments are the main channels for SO users to discuss
and communicate potential problems in answer posts. Ide-
ally, when a comment is posted to point out problem(s), it
should trigger an update in corresponding answers (e.g., code
snippets) and thus improve their quality. Nonetheless, because
digesting comments and manually maintaining answers (after
a long time being posted) are time-consuming and labor-
intensive, users seldom update code snippets based on com-
ments. As replied by an user in Stack Overflow [7] when
his/her obsolete answer was found, “ Feel free to update the
answer yourself, if you like. I honestly would, but I don’t have
the time.” Therefore, it is highly desirable to have a tool that
automatically updates SO code snippets according to the given
arXiv:2408.09095v1  [cs.SE]  17 Aug 2024
comments; however, developing such a tool poses significant
challenging, as outlined below:
• High quality dataset . Some previous works built datasets
for SO post updates; for example, Tang et al. [8] first
proposed a matching-based approach to map comments
to their related edits, building a dataset containing 248k
comment-edit pairs. However, due to the limitations of
their approach, the quality of their constructed dataset
can not be guaranteed. The recall of their method for
identifying valid comment-edit pairs is only 12.6%, while
the precision is 57.1%. The relatively low-quality data
greatly hinders the model’s performance trained on it. To
create such a dataset, it requires to extract valid comment-
edit pairs from SO, i.e., a comment and its corresponding
edit that addressed this comment. Currently, there is no
high-quality dataset available for training models that
automatically update posts.
• Post updating models . Even Tang et al. [8] proposed the
first comment-edit dataset, they ended up with creating
the dataset without further utilizing it. To the best of our
knowledge, there has been no research delving into the
automatic updating SO posts based on their comments.
To address the aforementioned challenges, we define two
key tasks as follows: (1) The Valid Comment-edit Prediction
(VCP). For a given SO answer post, numerous comments can
be added under the same post. However, not every comment
leads to an edit. In order to automatically construct a dataset
that can be used to train models for automatic post updating,
we defined this preliminary task. VCP is defined as predicting
whether a comment-edit pair is valid, and a valid comment-
edit pair is defined as: (i) the comment is relevant to the edit;
(ii) the edit addresses/implements all the issues/suggestions
raised in the comment; (iii) the edit does not make changes
beyond what is mentioned in the comment. In this type of
data, the updated code fully complies with the comments’
suggestions, and therefore, can be used to train the APU
model. (2) The Automatic Post Updating (APU). In Stack
Overflow, an edit is associated with a pair of posts before
and after modification. The APU task is defined as giving a
post before modification and its associated comment, whether
the post after modification can be correctly generated. Since
developers are more interested in code snippets, this paper
focuses only on the updating of code snippets in the posts.
Inspired by the great advancements and potential of Large
Language Models (LLMs) [9], [10], [11], [12], [13], [14],
[15], [16], [17] in code generation [18], [19], [20], [21], [22],
[23], [24], in this work, we proposed a novel LLM-based
framework, named SOUP (Stack Overflow Updator for Post),
to perform the VCP and APU tasks. For the VCP task, we
first manually annotated 5K comment-edit pairs, we then fine-
tuned a LLM for this task, and the trained model is denoted
as S OUP p. Then the well-trained model S OUP p is used to
automatically create a high quality dataset consisting of 78K
valid comment-edit pairs. This high-quality dataset is used for
fine-tuning a LLM on the APU task, and the trained model is
denoted as S OUP u. Our study aims to answer the following
four research questions:
1) RQ1: How effective is our approach in predicting
valid comment-edit pairs? We compared our S OUP p
with the matching-based method proposed by Tang et
al. [8], the experimental findings demonstrate that our
approach achieved an impressive 80.8% precision and
74.0% recall on the VCP task, marking a substantial
improvement over Tang’s method by 42% and 487%
respectively.
2) RQ2: How effective is our approach in automatically
updating SO code snippets based on their com-
ments? The experimental results show that our approach
achieved a 25.6% exact match rate, particularly excelling
in solving improvement-type updates.
3) RQ3: To what extent does the dataset influence
model performance in the APU task? We performed
a cross-dataset evaluation between different models, the
experimental results show that the model trained on our
dataset significantly outperformed the same one trained
on Tang’s [8] proposed dataset.
4) RQ4: How acceptable are our updated SO posts in
real-world scenarios? In this RQ, we conducted an
in-the-wild evaluation to evaluate the effectiveness of
SOUP in practice. We randomly sampled 50 unaddressed
comments from SO, we then manually submitted S OUP
generated edits to these posts, 21 updates are accepted
by SO maintainers.
Overall, our paper makes the following contributions:
• We propose a novel LLM-based framework , S OUP,
to accurately predict valid comment-edit pairs and au-
tonomously update SO code snippets based on associated
comments. S OUP is expected to become a real-time up-
dating tool for code forum websites, ultimately improving
the code quality of such sites. .
• We build a high quality dataset for SO post updating,
which contains 78,317 valid comment-edit pairs for Java,
the experimental results show that our constructed high
quality dataset can significantly improve model’s perfor-
mance on the APU task.
• We extensively evaluate our approach by submitting
SOUP suggested edits to actual SO posts. 21 edits are
accepted, verifying the practical value of our approach.
• Our contribution also lies in the provision of both the
source code and dataset [25] for S OUP, enabling fellow
researchers to replicate our findings and explore their own
concepts with ease.
II. M OTIVATION
Although SO code snippets may not always be flawless, the
platform’s comments serve as valuable resources for identify-
ing potential issues and offering constructive feedback. Fig. 2
shows several comment-edit examples in SO to deliver helpful
information and knowledge for different problems. (1) Even
popular SO answers may contain problematic code snippets.
Ex1. Comment : LinkedList should be replaced by ArrayList but LinkedHashMap is necessary because it preserves insertion order. (PostID:2581754)public class MapUtil {        public static <K, V extends Comparable<? super V>> Map<K, V>                sortByValue(Map<K, V>map)                List<Map.Entry<K, V>> list = new LinkedList<MapArrayList<Map.Entry<K, V>>(map.entrySet());                …..
Ex3. Comment : I know this is an old post, but It is worth mentioning to other visitors that the above code has a bug. One must use thenextTokenwhen calling tosnsClient.listTopics()otherwise you will have an infinite loop (provided you have more than 100 topics). (PostID:2556190)public class TestSNS {                …..                while (nextToken != null) {                        listTopicsResult = snsClient.listTopics(nextToken);                 ……
Ex2. Comment : Use the proper add (…) method. The add(String, Component) method has been obsolete for over a decade, since JDK1.1. (PostID:39134628)JPanel sidePanel = new JPanel(new BorderLayout());                  …..sidePanel.add(BorderLayout.CENTER, new JScrollPane(log), BorderLayout.CENTER); sidePanel.add(buttonPanel, BorderLayout.NORTH, buttonPanel);  ……
Fig. 2. Motivating Examples
For example, Ex.1 presents a suboptimal code snippet, the
question post “ sort a Map ⟨Key, Value⟩ by values ” received
more than 1.8k votes and has been visited for more than 1.8m
times since its creation, and this code snippet received more
than 1k votes by SO users. However, as suggested by a devel-
oper, this code snippet is suboptimal by using LinkedList
instead of ArrayList. After the comment was posted, the
answer post was subsequently updated accordingly. However,
it is worth noting that this problematic code had been present
on SO for over eight years before any editing took place. (2)
SO answers may become obsolete or outdated as a result of
the rapid evolution of software systems. Ex.2 demonstrates an
example where the code snippet used an outdated method add
which has been obsolete for over a decade. (3) SO answers
may contain buggy code. An example is shown in Ex.3, as
the commenter pointed out, “ I know this is an old post, but
it is worth mentioning to other visitors the above code has a
bug. One must use nextToken ..., otherwise you will have
an infinite loop ”. This answer post was created in August
2014, but this bug has not been discovered until July 2015.
During this time, this code snippet was visited by SO users
thousands of times, which can mislead developers and cause
the introduction of bugs in their subsequent development.
SO comments provide valuable information to improve the
code snippet’s quality, however, prior studies [3], [4] found
that answers are rarely updated after comments are posted, and
only 4.6% of the answers are edited after any comments [26].
In other words, the valuable information hidden in comments
is mostly ignored and the comments are rarely integrated back
into answers. Therefore, in this work, we aim to fill this gap by
proposing a tool to automatically update code snippets based
on their associated comments, which can enhance the answer
quality and reduce the likelihood of introducing bugs.
III. P RELIMINARY INVESTIGATION
Tang et al. [8] conducted the first study on how to map
a comment with its associated edit. They proposed a simple
False Negative Example - Comment: hello, thank you, but I don't wanna close the whole program,
just the window where i am. (PostID: 41343549)
if(salir != 0){
System.exit(0) nameofyourframe.dispose();
}
False Positive Example - Comment: Rather than declare the activity as singleInstance, consider
using FLAG_ACTIVITY_CLEAR_TOP|FLAG_ACTIVITY_SINGLE_TOP as the flags for the Intent. This will
finish intervening activities and start (or bring back to the foreground) the desired activity. (PostID:
6330456)
……
intent.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP FLAG_ACTIVITY_NEW_TASK | 
Intent.FLAG_ACTIVITY_CLEAR_TASK);
……
Fig. 3. Preliminary Investigation Examples
matching-based method to determine whether an edit is related
to a comment. Specifically, their method matches a comment
to an edit based on three heuristic rules: (1) the comment
occurred before the edit; (2) the comment mentions a code
term that gets added or removed from a code snippet within
the edit; (3) the commenter and the editor are different users.
To evaluate their method performance, Tang et al. manually
annotated 194 comment-edit pairs (from 100 SO posts) to
create a ground truth dataset for estimating the precision and
recall of their approach. As they reported, their matching-
based method achieved 70% precision and 32% recall on this
ground truth dataset. They further analyzed 1,910 positive
cases (including 382 Java cases) predicted by their method and
reported a precision of 78%. To gain a deeper understanding of
their method and dataset, we manually investigated 382 Java
comment-edit pairs predicted as relevant by their method and
found the following limitations:
• Tang’s method of using human-defined rules to predict
the relevance of edits and comments has two disadvan-
tages: first, it ignores the semantic relationship between
code terms and edits ; second, relevant comment-edit
pairs are not necessarily valid comment-edit pairs .
Fig. 3 shows a false positive example, the comment men-
tions the code term FLAG_ACTIVITY_CLEAR_TOP
that was deleted in the edits, Tang’s method predicted
this comment-edit pair as relevant. However, the edit
did not modify according to the comment’s suggestions
(use FLAG_ACTIVITY_SINGLE_TOP). Such pairs are
considered as relevant by Tang et al. but failed to meet
our valid comment-edit pair definition. We relabeled these
382 pairs with standards of our valid comment-edit pairs
and reevaluated Tang’s method, the precision of Tang’s
method significantly dropped from 70% to 56%.
• There are a large number of SO comments that caused
an edit but did not contain any code terms, resulting
in a large number of false negative samples. Fig. 3 shows
a false negative example where the comment doesn’t
mention any code terms. Tang’s method can’t identify
such comment-edit pairs because the comment does not
use explicit code terms but rather explains the problem
and how the code can be fixed. This limitation makes their
method miss a significant number of valid comment-edit
pairs, resulting in notably low recall scores.
Although Tang et al. constructed the first relevant comment-