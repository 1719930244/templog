# 杨光（Guang Yang）论文：PDF 可得性与写作信号汇总

- 生成时间（UTC）：`2026-02-10T01:57:15.573579+00:00`
- 条目数：`39`（按 publications 页解析）
- 成功下载 PDF：`6` / `39`（15.4%）

## 下载到的 PDF（可用于细读）
- 2021 SEKE'21 DeepSCC: Source Code Classification Based on Fine-Tuned RoBERTa (S) (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2021_SEKE'21_DeepSCC_ Source Code Classification Based on Fine-Tuned RoBERTa (S)_19893a4e0c50.pdf`)
- 2022 ICBASE'22 BUG-T5: A Transformer-based Automatic Title Generation Method for Bug Reports (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2022_ICBASE'22_BUG-T5_ A Transformer-based Automatic Title Generation Method for Bug Reports_56fc71c3dc96.pdf`)
- 2023 EMNLP'23 Syntax-Aware Retrieval Augmented Code Generation (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2023_EMNLP'23_Syntax-Aware Retrieval Augmented Code Generation_be5d808eb27a.pdf`)
- 2023 SEKE'23 An Empirical Study of Adversarial Training in Code Comment Generation (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2023_SEKE'23_An Empirical Study of Adversarial Training in Code Comment Generation_b6f9f464f2b4.pdf`)
- 2023 SEKE'23 CCGRA: Smart Contract Code Comment Generation with Retrieval-enhanced Approach (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2023_SEKE'23_CCGRA_ Smart Contract Code Comment Generation with Retrieval-enhanced Approach_0dd06bcf5f27.pdf`)
- 2024 计算机研究与发展'24 CodeScore-R：用于评估代码合成功能准确性的自动化鲁棒指标 (`C:\Users\daoge\Desktop\codes\写作参考\papers\pdfs_yg\2024_计算机研究与发展'24_CodeScore-R：用于评估代码合成功能准确性的自动化鲁棒指标_c616c8d692cb.pdf`)

## 标题风格信号（全量条目）

| 信号 | 命中数 | 占比 |
|---|---:|---:|
| `has_colon` | 22 | 56.4% |
| `has_question` | 1 | 2.6% |
| `has_towards` | 1 | 2.6% |
| `has_less_is_more` | 2 | 5.1% |
| `has_acronym` | 7 | 17.9% |

## 摘要信号（全量条目；按语言分组）

### English abstracts (`38`)

| 信号 | 命中数 | 占比 |
|---|---:|---:|
| `has_numbers` | 25 | 65.8% |
| `has_action_verb` | 33 | 86.8% |
| `has_gap_phrase` | 5 | 13.2% |
| `has_results` | 25 | 65.8% |

### 中文摘要 (`1`)

| 信号 | 命中数 | 占比 |
|---|---:|---:|
| `has_numbers` | 1 | 100.0% |
| `has_propose` | 1 | 100.0% |
| `has_results` | 0 | 0.0% |

## PDF 结构信号（下载成功子集）

| 信号 | 命中数 | 占比 |
|---|---:|---:|
| `has_abstract_heading` | 6 | 100.0% |
| `has_introduction_heading` | 2 | 33.3% |
| `has_contributions_phrase` | 0 | 0.0% |
| `has_rq` | 2 | 33.3% |
| `has_threats_to_validity` | 0 | 0.0% |
| `has_evaluation_section` | 6 | 100.0% |
| `mentions_tool_or_implementation` | 4 | 66.7% |
| `abstract_has_numbers` | 6 | 100.0% |

## 未能获取公开 PDF 的条目（需要你手动或校内/机构访问下载）
- 2021 APSEC'21 Fine-grained Pseudo-code Generation Method via Code Feature Extraction and Transformer（pdf_source=none ）
- 2021 DSA'21 ComFormer: Code Comment Generation via Transformer and Fusion Method-based Hybrid Code Representation（pdf_source=none ）
- 2021 DSA'21 EKD-BSP: Bug Report Severity Prediction by Extracting Keywords from Description（pdf_source=none ）
- 2021 吉林大学学报 (理学版)'21 基于深度学习的 Stack Overflow 问题帖分类方法（pdf_source=none ）
- 2021 计算机应用研究'21 ORESP:基于有序回归的软件缺陷严重程度预测方法（pdf_source=none ）
- 2021 软件学报'21 代码注释自动生成方法综述（pdf_source=none ）
- 2022 ICSME'22 BashExplainer: Retrieval-Augmented Bash Code Comment Generation based on Fine-tuned CodeBERT（pdf_source=none ）
- 2022 Internetware'22 EL-CodeBert: Better Exploiting CodeBert to Support Source Code-Related Classification Tasks（pdf_source=none ）
- 2022 KBS'22 CCGIR: Information retrieval-based code comment generation method for smart contracts（pdf_source=none ）
- 2022 SANER'22 DualSC: Automatic Generation and Summarization of Shellcode via Transformer and Dual Learning（pdf_source=none ）
- 2022 SANER'22 SOTitle: A Transformer-based Post Title Generation Approach for Stack Overflow（pdf_source=none ）
- 2023 COMPSAC'23 EDP-BGCNN: Effective Defect Prediction via BERT-based Graph Convolutional Neural Network（pdf_source=none ）
- 2023 EMSE'23 A syntax-guided multi-task learning approach for Turducken-style code generation（pdf_source=none ）
- 2023 JSS'23 ExploitGen: Template-augmented exploit code generation based on CodeBERT（pdf_source=none ）
- 2023 软件学报'23 基于双重信息检索的Bash代码注释生成方法（pdf_source=none ）
- 2024 ASEJ'24 Bash comment generation via data augmentation and semantic-aware CodeBERT（pdf_source=none ）
- 2024 EMSE'24 Automatic bi-modal question title generation for Stack Overflow with prompt learning（pdf_source=none ）
- 2024 ICCTIT'24 RegexExplainer: Automatic Description Generation for Regular Expressions via Transformer（pdf_source=none ）
- 2024 IST'24 Automatic smart contract comment generation via large language models and in-context learning（pdf_source=none ）
- 2024 JSS'24 Context-aware code generation with synchronous bidirectional decoder（pdf_source=none ）
- 2024 TOSEM'24 How important are good method names in neural code generation? a model robustness perspective（pdf_source=none ）
- 2024 TSE'24 Chain-of-Thought in Neural Code Generation: From and for Lightweight Language Models（pdf_source=none ）
- 2025 ACL'25 Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation（pdf_source=none ）
- 2025 ASE'25 Code-DiTing: Automatic Evaluation of Code Generation without References or Test Cases（pdf_source=none ）
- 2025 ASE'25 Evaluating and Improving Framework-based Parallel Code Completion with Large Language Models（pdf_source=none ）
- 2025 ASE'25 SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE（pdf_source=none ）
- 2025 EAAI'25 Resource-efficient automatic software vulnerability assessment via knowledge distillation and particle swarm optimization（pdf_source=none ）
- 2025 IST'25 Assessing and improving syntactic adversarial robustness of pre-trained models for code translation（pdf_source=none ）
- 2025 Preprints'25 Large Language Model for Verilog Code Generation: Literature Review and the Road Ahead（pdf_source=openalex HTTPError: HTTP Error 403: Forbidden）
- 2025 TSE'25 Anchor Attention, Small Cache: Code Generation With Large Language Models（pdf_source=none ）
- 2026 IPM'26 Less is More: Towards Green Code Large Language Models via Unified Structural Pruning（pdf_source=none ）
- 2026 TOSEM'26 Defending Code Language Models against Backdoor Attacks with Deceptive Cross-Entropy Loss（pdf_source=none ）
- 2026 TOSEM'26 Less is More: DocString Compression in Code Generation（pdf_source=none ）

